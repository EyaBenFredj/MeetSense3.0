# ğŸ§  MeetSense : AI Meeting Assistant
**Multilingual AI-powered tool for meeting transcription and knowledge retrieval (Tunisian dialect, French, English).**

This project provides:
- ğŸ™ï¸ **Accurate meeting transcription** using OpenAI Whisper & Faster-Whisper  
- ğŸŒ **Multilingual processing** (Tunisian dialect, Arabic script, French, English)  
- ğŸ”¤ **Smart acronym expansion** & transliteration of Arabic-script words  
- ğŸ“š **Knowledge base search** over saved transcripts  
- ğŸ‘¤ **User management system** (login, signup, transcript storage)  
- ğŸ’» **Web interfaces** with Streamlit 
---

## ğŸš€ Features
- Upload audio in multiple formats (`.mp3`, `.wav`, `.m4a`, `.mp4`)
- Automatic **language detection**
- Handles **Tunisian dialect**, Arabic, French, and English seamlessly
- Expands **acronyms** automatically (via `core.acronyms.expander`)
- **Transliterates Arabic-script words** into Latin script where necessary
- **Noise reduction** & audio preprocessing for clearer transcription
- Secure **user accounts** with personal transcript history
- Integrated **search engine** for knowledge retrieval across meetings

---
---

## ğŸ”¹ Demo Previews

Below are some demo screenshots that showcase **MeetSense in action**:

### 1. Streamlit Interface
MeetSense provides an **interactive Streamlit interface** for quickly uploading and processing meeting recordings.  
This interface is lightweight and ideal for prototyping and internal usage.

<img width="1918" height="896" alt="streamlit" src="https://github.com/user-attachments/assets/0c34fc3e-37a6-4431-96ce-60ac2b9bfb56" />

---

### 2. React Extension Prototype
We also built a **React-based interface**, designed to evolve into a **browser extension or standalone web app**.  
This architecture makes it easier to integrate MeetSense into existing workflows (e.g., Google Meet, Zoom, MS Teams)  
and ensures scalability beyond the Streamlit prototype.

<img width="1897" height="986" alt="react interface" src="https://github.com/user-attachments/assets/7ea14b7b-5742-41b0-986c-256872576c04" />

---

### 3. Execution Example â€“ French Transcription
MeetSense can **transcribe meetings directly in French** (or any other supported language).  
Here, an audio snippet is automatically detected as French and converted into clean text, then saved into a transcript file.

<img width="1491" height="807" alt="dem2" src="https://github.com/user-attachments/assets/6f8710f5-190f-4697-a5d0-bae1c28de995" />

---

### 4. Execution Example â€“ Transcription + Acronym Detection
Beyond transcription, MeetSense also performs **acronym detection and expansion**.  
In this example:
- The raw transcript is first generated in mixed languages.  
- Acronyms such as `DD`, `MT`, `QA`, `RM`, and `SP` are automatically spotted.  
- A second, enriched transcript is created where acronyms are expanded for clarity (e.g., *SP â†’ Sofrecom Products*).  

This feature ensures meeting transcripts are **readable and knowledge-rich**, even when shorthand or domain-specific terms are used.

<img width="1492" height="842" alt="dem1" src="https://github.com/user-attachments/assets/ed1f0b96-e78a-4655-bb8a-caeb5744bb27" />
---
## ğŸ“‚ Project Structure
```
MeetSense3.0/
â”‚
â”œâ”€â”€ .venv/                         # Virtual environment
â”œâ”€â”€ .env                           # Environment variables (API keys, configs)
â”œâ”€â”€ .gitignore                     # Git ignored files
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # Project documentation
â”‚
â”œâ”€â”€ app.py                         # Main Streamlit application
â”œâ”€â”€ pipeline.py                    # Central transcription pipeline orchestration
â”œâ”€â”€ whisper_transcript.txt         # Example transcript output
â”œâ”€â”€ temp_Enregistrement.m4a        # Sample audio recording
â”œâ”€â”€ users.db                       # SQLite database for users & transcripts
â”‚
â”œâ”€â”€ whisper_streaming/              # Whisper streaming tests & modules
â”‚
â”œâ”€â”€ Transcription/                  # Speech-to-text & processing modules
â”‚   â”œâ”€â”€ record_voice.py             # Record audio from microphone
â”‚   â”œâ”€â”€ preprocess_audio.py         # Preprocess & denoise audio
â”‚   â”œâ”€â”€ transcribe_audio.py         # Core Whisper/Faster-Whisper transcription
â”‚   â”œâ”€â”€ process_transcript.py       # Acronym expansion & transliteration
â”‚   â”œâ”€â”€ punctuate.py                # Restores punctuation in transcripts
â”‚   â”œâ”€â”€ stream_transcribe.py        # Streaming transcription logic
â”‚   â”œâ”€â”€ run_pipeline.py             # Runs full transcription pipeline
â”‚   â”œâ”€â”€ run_pipeline2.py            # Alternative pipeline runner
â”‚   â”œâ”€â”€ test_whisper.py             # Test script for Whisper
â”‚   â”œâ”€â”€ test_whisper2.py
â”‚   â”œâ”€â”€ test_whisper3.py
â”‚   â”œâ”€â”€ bullet_points.txt           # Example bullet point summary
â”‚   â”œâ”€â”€ expanded_transcript.txt     # Transcript with acronyms expanded
â”‚   â”œâ”€â”€ original_transcript.txt     # Raw transcript output
â”‚   â”œâ”€â”€ transcript.txt              # Processed transcript
â”‚   â”œâ”€â”€ translated_french.txt       # Transcript translated into French
â”‚   â”œâ”€â”€ summary.txt                 # Example transcript summary
â”‚   â”œâ”€â”€ whisper_transcript.txt      # Whisper-generated transcript
â”‚   â””â”€â”€ my_voice.wav                # Example input audio file
â”‚
â”œâ”€â”€ Knowledge Extraction & Retrieval/ # Semantic + keyword transcript search
â”‚   â””â”€â”€ (Modules for retrieval & knowledge indexing)
â”‚
â”œâ”€â”€ PostProcessing & Summarization/ # Transcript summarization modules
â”‚   â””â”€â”€ summarize.py                # Generates abstractive meeting summaries
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_acronym_registry.py   # Builds acronym registry for expansion
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ acronym_seed.py             # Initial acronym seeds for registry
â”‚
â”œâ”€â”€ acronym_index/                  # Vector store for acronyms
â”‚   â”œâ”€â”€ index_builder.py            # Builds acronym vector index
â”‚   â”œâ”€â”€ default_vector_store.json   # Default embedding store
â”‚   â”œâ”€â”€ docstore.json               # Document storage
â”‚   â”œâ”€â”€ graph_store.json            # Graph relationships between acronyms
â”‚   â”œâ”€â”€ image_vector_store.json     # (Future) embeddings for images
â”‚   â””â”€â”€ index_store.json            # Finalized index structure
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ acronyms.py                 # Acronym expansion logic
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ chat_chain.py               # Conversational pipeline for Q&A
â”‚
â”œâ”€â”€ data/                           # User data & transcripts
â”‚   â”œâ”€â”€ audio/                      # Uploaded audio files
â”‚   â”œâ”€â”€ transcripts/                # Saved transcripts per user
â”‚   â”œâ”€â”€ uploads/                    # Temporary upload files
â”‚   â”œâ”€â”€ acronyms.json               # Acronym dictionary
â”‚   â”œâ”€â”€ meetings.db                 # Meeting metadata database
â”‚   â””â”€â”€ users.json                  # User authentication data
â”‚
â”œâ”€â”€ Interface/
â”‚   â”œâ”€â”€ Pages/                      # Streamlit modular pages
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ asr.py                  # Automatic Speech Recognition page
â”‚   â”‚   â”œâ”€â”€ auth.py                 # Login & signup page
â”‚   â”‚   â”œâ”€â”€ knowledge.py            # Knowledge base search page
â”‚   â”‚   â””â”€â”€ storage.py              # Transcript storage & management
```


## ğŸ“¦ Installation

1. Clone the repo:
```bash
git clone https://github.com/EyaBenFredj/MeetSense3.0
cd MeetSense3.0
````

2. Create virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ§© Dependencies

* **flask** â€“ API endpoints (future expansion)
* **vosk** â€“ optional offline transcription
* **sounddevice, scipy, numpy, pydub, librosa, soundfile, noisereduce** â€“ audio preprocessing
* **whisper, faster-whisper** â€“ multilingual transcription
* **torch, torchaudio** â€“ deep learning backend
* **transformers, spacy** â€“ NLP pipeline
* **langdetect, translit-me** â€“ language detection & transliteration
* **llama-index** â€“ semantic knowledge retrieval
* **sqlalchemy** â€“ structured storage
* ** streamlit** â€“ interfaces (demo + full app)

---

## âš™ï¸ Workflow

1. **Audio Input**
   User records/upload audio â†’ stored in `/data/audio/`

2. **Preprocessing**

   * Noise reduction (`noisereduce`, `pydub`)
   * Resampling & normalization (`librosa`, `soundfile`)

3. **Transcription**

   * Whisper/Faster-Whisper transcribes
   * Language auto-detected (Arabic, French, English)

4. **Post-Processing**

   * Acronym expansion (`core/acronyms.py`)
   * Script detection & transliteration (`translit-me`)
   * Punctuation restoration

5. **Knowledge Management**

   * Transcript saved to `/data/transcripts/<user>/`
   * Indexed into `Knowledge Extraction & Retrieval`

6. **Search & Summarization**

   * Keyword + semantic search (LLaMA-Index)
   * Summarization (`summarize.py`, `bullet_points.py`)

7. **User Management**

   * Users stored in `users.json` or `users.db`
   * Each has personal transcripts

---

## ğŸ§  Models & LLMs

* **Whisper/Faster-Whisper**: Transcription (Tunisian dialect + French + English)
* **SpaCy/Transformers**: Text tokenization, NER
* **Langdetect + Translit-me**: Language detection + transliteration
* **LLaMA-Index**: Semantic knowledge base
* **Custom Acronym Index**: Consistent acronym handling

---

## ğŸ—ï¸ Challenges Faced

* **Dialect mixing**: Tunisian Arabic often mixed with French/English â†’ solved with transliteration + hybrid language detection
* **Noisy audio**: solved with preprocessing & `noisereduce`
* **Acronym expansion**: built custom registry with first-use expansion
* **User data**: managed with JSON/SQLite, scalable to SQLAlchemy
* **Search**: balanced between keyword speed & semantic embeddings

---

## â–¶ï¸ Running the App


### Streamlit Web App

```bash
streamlit run app.py
```

Go to: `http://localhost:8501`

---

## ğŸ“Œ Roadmap

* [ ] Multi-speaker diarization
* [ ] OAuth-based authentication
* [ ] Dockerized deployment
* [ ] Full SQLAlchemy migration
* [ ] Fine-tuned summarization models

---



# ğŸ“ PostProcessing & Summarization

Handles transcript cleanup and summarization.

## Files
- `summarize.py` â†’ abstractive meeting summarization
- `bullet_points.py` (output) â†’ action items

## Workflow
1. Input transcript
2. Clean text
3. Generate bullet points or summaries



# ğŸ“š Knowledge Extraction & Retrieval

Implements knowledge base search.

## Features
- Index transcripts with LLaMA-Index
- Keyword search fallback
- Hybrid retrieval (semantic + keyword)

## Workflow
1. User query
2. Search transcripts (keyword + embeddings)
3. Return matching segments





