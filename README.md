# ğŸ§  MeetSense : AI Meeting Assistant
**Multilingual AI-powered tool for meeting transcription and knowledge retrieval (Tunisian dialect, French, English).**

This project provides:
- ğŸ™ï¸ **Accurate meeting transcription** using OpenAI Whisper & Faster-Whisper  
- ğŸŒ **Multilingual processing** (Tunisian dialect, Arabic script, French, English)  
- ğŸ”¤ **Smart acronym expansion** & transliteration of Arabic-script words  
- ğŸ“š **Knowledge base search** over saved transcripts  
- ğŸ‘¤ **User management system** (login, signup, transcript storage)  
- ğŸ’» **Web interfaces** with Streamlit & Gradio  

---

## ğŸš€ Features
- Upload audio in multiple formats (`.mp3`, `.wav`, `.m4a`, `.mp4`)
- Automatic **language detection**
- Handles **Tunisian dialect**, Arabic, French, and English seamlessly
- Expands **acronyms** automatically (via `core.acronyms.expander`)
- **Transliterates Arabic-script words** into Latin script where necessary
- **Noise reduction** & audio preprocessing for clearer transcription
- Secure **user accounts** with personal transcript history
- Integrated **search engine** for knowledge retrieval across meetings

---
## ğŸ“‚ Project Structure
```
MeetSense3.0/
â”‚
â”œâ”€â”€ .venv/                         # Virtual environment
â”œâ”€â”€ .env                           # Environment variables (API keys, configs)
â”œâ”€â”€ .gitignore                     # Git ignored files
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # Project documentation
â”‚
â”œâ”€â”€ app.py                         # Main Streamlit application
â”œâ”€â”€ pipeline.py                    # Central transcription pipeline orchestration
â”œâ”€â”€ whisper_transcript.txt         # Example transcript output
â”œâ”€â”€ temp_Enregistrement.m4a        # Sample audio recording
â”œâ”€â”€ users.db                       # SQLite database for users & transcripts
â”‚
â”œâ”€â”€ whisper_streaming/              # Whisper streaming tests & modules
â”‚
â”œâ”€â”€ Transcription/                  # Speech-to-text & processing modules
â”‚   â”œâ”€â”€ record_voice.py             # Record audio from microphone
â”‚   â”œâ”€â”€ preprocess_audio.py         # Preprocess & denoise audio
â”‚   â”œâ”€â”€ transcribe_audio.py         # Core Whisper/Faster-Whisper transcription
â”‚   â”œâ”€â”€ process_transcript.py       # Acronym expansion & transliteration
â”‚   â”œâ”€â”€ punctuate.py                # Restores punctuation in transcripts
â”‚   â”œâ”€â”€ stream_transcribe.py        # Streaming transcription logic
â”‚   â”œâ”€â”€ run_pipeline.py             # Runs full transcription pipeline
â”‚   â”œâ”€â”€ run_pipeline2.py            # Alternative pipeline runner
â”‚   â”œâ”€â”€ test_whisper.py             # Test script for Whisper
â”‚   â”œâ”€â”€ test_whisper2.py
â”‚   â”œâ”€â”€ test_whisper3.py
â”‚   â”œâ”€â”€ bullet_points.txt           # Example bullet point summary
â”‚   â”œâ”€â”€ expanded_transcript.txt     # Transcript with acronyms expanded
â”‚   â”œâ”€â”€ original_transcript.txt     # Raw transcript output
â”‚   â”œâ”€â”€ transcript.txt              # Processed transcript
â”‚   â”œâ”€â”€ translated_french.txt       # Transcript translated into French
â”‚   â”œâ”€â”€ summary.txt                 # Example transcript summary
â”‚   â”œâ”€â”€ whisper_transcript.txt      # Whisper-generated transcript
â”‚   â””â”€â”€ my_voice.wav                # Example input audio file
â”‚
â”œâ”€â”€ Knowledge Extraction & Retrieval/ # Semantic + keyword transcript search
â”‚   â””â”€â”€ (Modules for retrieval & knowledge indexing)
â”‚
â”œâ”€â”€ PostProcessing & Summarization/ # Transcript summarization modules
â”‚   â””â”€â”€ summarize.py                # Generates abstractive meeting summaries
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_acronym_registry.py   # Builds acronym registry for expansion
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ acronym_seed.py             # Initial acronym seeds for registry
â”‚
â”œâ”€â”€ acronym_index/                  # Vector store for acronyms
â”‚   â”œâ”€â”€ index_builder.py            # Builds acronym vector index
â”‚   â”œâ”€â”€ default_vector_store.json   # Default embedding store
â”‚   â”œâ”€â”€ docstore.json               # Document storage
â”‚   â”œâ”€â”€ graph_store.json            # Graph relationships between acronyms
â”‚   â”œâ”€â”€ image_vector_store.json     # (Future) embeddings for images
â”‚   â””â”€â”€ index_store.json            # Finalized index structure
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ acronyms.py                 # Acronym expansion logic
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ chat_chain.py               # Conversational pipeline for Q&A
â”‚
â”œâ”€â”€ data/                           # User data & transcripts
â”‚   â”œâ”€â”€ audio/                      # Uploaded audio files
â”‚   â”œâ”€â”€ transcripts/                # Saved transcripts per user
â”‚   â”œâ”€â”€ uploads/                    # Temporary upload files
â”‚   â”œâ”€â”€ acronyms.json               # Acronym dictionary
â”‚   â”œâ”€â”€ meetings.db                 # Meeting metadata database
â”‚   â””â”€â”€ users.json                  # User authentication data
â”‚
â”œâ”€â”€ Interface/
â”‚   â”œâ”€â”€ Pages/                      # Streamlit modular pages
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ asr.py                  # Automatic Speech Recognition page
â”‚   â”‚   â”œâ”€â”€ auth.py                 # Login & signup page
â”‚   â”‚   â”œâ”€â”€ knowledge.py            # Knowledge base search page
â”‚   â”‚   â””â”€â”€ storage.py              # Transcript storage & management
```


## ğŸ“¦ Installation

1. Clone the repo:
```bash
git clone https://github.com/your-repo/MeetSense3.0.git
cd MeetSense3.0
````

2. Create virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ§© Dependencies

* **flask** â€“ API endpoints (future expansion)
* **vosk** â€“ optional offline transcription
* **sounddevice, scipy, numpy, pydub, librosa, soundfile, noisereduce** â€“ audio preprocessing
* **whisper, faster-whisper** â€“ multilingual transcription
* **torch, torchaudio** â€“ deep learning backend
* **transformers, spacy** â€“ NLP pipeline
* **langdetect, translit-me** â€“ language detection & transliteration
* **llama-index** â€“ semantic knowledge retrieval
* **sqlalchemy** â€“ structured storage
* **gradio, streamlit** â€“ interfaces (demo + full app)

---

## âš™ï¸ Workflow

1. **Audio Input**
   User records/upload audio â†’ stored in `/data/audio/`

2. **Preprocessing**

   * Noise reduction (`noisereduce`, `pydub`)
   * Resampling & normalization (`librosa`, `soundfile`)

3. **Transcription**

   * Whisper/Faster-Whisper transcribes
   * Language auto-detected (Arabic, French, English)

4. **Post-Processing**

   * Acronym expansion (`core/acronyms.py`)
   * Script detection & transliteration (`translit-me`)
   * Punctuation restoration

5. **Knowledge Management**

   * Transcript saved to `/data/transcripts/<user>/`
   * Indexed into `Knowledge Extraction & Retrieval`

6. **Search & Summarization**

   * Keyword + semantic search (LLaMA-Index)
   * Summarization (`summarize.py`, `bullet_points.py`)

7. **User Management**

   * Users stored in `users.json` or `users.db`
   * Each has personal transcripts

---

## ğŸ§  Models & LLMs

* **Whisper/Faster-Whisper**: Transcription (Tunisian dialect + French + English)
* **SpaCy/Transformers**: Text tokenization, NER
* **Langdetect + Translit-me**: Language detection + transliteration
* **LLaMA-Index**: Semantic knowledge base
* **Custom Acronym Index**: Consistent acronym handling

---

## ğŸ—ï¸ Challenges Faced

* **Dialect mixing**: Tunisian Arabic often mixed with French/English â†’ solved with transliteration + hybrid language detection
* **Noisy audio**: solved with preprocessing & `noisereduce`
* **Acronym expansion**: built custom registry with first-use expansion
* **User data**: managed with JSON/SQLite, scalable to SQLAlchemy
* **Search**: balanced between keyword speed & semantic embeddings

---

## â–¶ï¸ Running the App

### CLI

```bash
python app_int.py
```

### Streamlit Web App

```bash
streamlit run app.py
```

Go to: `http://localhost:8501`

---

## ğŸ“Œ Roadmap

* [ ] Multi-speaker diarization
* [ ] OAuth-based authentication
* [ ] Dockerized deployment
* [ ] Full SQLAlchemy migration
* [ ] Fine-tuned summarization models

---



# ğŸ“ PostProcessing & Summarization

Handles transcript cleanup and summarization.

## Files
- `summarize.py` â†’ abstractive meeting summarization
- `bullet_points.py` (output) â†’ action items

## Workflow
1. Input transcript
2. Clean text
3. Generate bullet points or summaries
```

---


# ğŸ“š Knowledge Extraction & Retrieval

Implements knowledge base search.

## Features
- Index transcripts with LLaMA-Index
- Keyword search fallback
- Hybrid retrieval (semantic + keyword)

## Workflow
1. User query
2. Search transcripts (keyword + embeddings)
3. Return matching segments
```

---


# ğŸ”¤ Core Module

Core utilities for acronyms.

- `acronyms.py` â†’ acronym registry & expansion logic

Workflow:
- On first mention â†’ expand with full form (e.g. *Artificial Intelligence (AI)*)
- Later mentions â†’ shortened (*AI*)
```

---



# ğŸ—‚ï¸ Acronym Index

Vector-based storage of acronyms.

- `index_builder.py` â†’ builds vector index
- `default_vector_store.json` â†’ embeddings store
- `docstore.json`, `graph_store.json`, `image_vector_store.json`, `index_store.json` â†’ index persistence
```

---

