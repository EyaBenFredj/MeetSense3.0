import json
import wave
import os
from vosk import Model, KaldiRecognizer

# ğŸŒ Multilingual context vocabulary (Tunisian Arabic + French + English)
CONTEXT_PHRASES = {
    "work_meeting": [
        "projet", "meeting", "rÃ©union", "client", "ØªØ®Ø·ÙŠØ·", "planning", "objectif", "Ù…ÙŠØ²Ø§Ù†ÙŠØ©",
        "startup", "ØªØ³ÙŠÙŠØ±", "gestion", "timeline", "deadlines", "Ù…Ø³Ø¤ÙˆÙ„", "responsable", "strategy"
    ],
    "networks_fiber": [
        "fiber", "fibre optique", "backbone", "5G", "dÃ©ploiement", "Ø´Ø¨ÙƒØ©", "ØªØºØ·ÙŠØ©", "connexion",
        "haut dÃ©bit", "FTTx", "latency", "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±ÙŠØ¶", "capacitÃ©", "architecture rÃ©seau"
    ],
    "it_security": [
        "cybersecurity", "sÃ©curitÃ©", "Ø§Ø®ØªØ±Ø§Ù‚", "firewall", "ØªØ­Ù‚Ù‚", "authentification", "Ù…Ø±Ø§Ù‚Ø¨Ø©",
        "antivirus", "intrusion", "compliance", "SOC", "privileges", "ÙƒÙ„Ù…Ø© Ø³Ø±", "protection", "data leak"
    ],
    "data_ai": [
        "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "machine learning", "model", "donnÃ©es", "data", "analyse prÃ©dictive",
        "predictive maintenance", "Ù…Ø¹Ø§Ù„Ø¬Ø©", "Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©", "algorithm", "Ù†Ù…ÙˆØ°Ø¬", "training", "AI", "optimisation"
    ],
    "consulting_transform": [
        "digital transformation", "ØªØ­ÙˆÙ„ Ø±Ù‚Ù…ÙŠ", "governance", "agile", "scrum", "ØªØ·ÙˆÙŠØ±", "workflow",
        "pilotage", "impact", "pÃ©rimÃ¨tre", "efficacitÃ©", "sustainability", "ØªØºÙŠÙŠØ±", "change management"
    ]
}


def select_context():
    print("ğŸ”§ Select meeting context:")
    options = list(CONTEXT_PHRASES.keys())
    for i, key in enumerate(options, 1):
        print(f"{i}. {key.replace('_', ' ').title()}")
    choice = input("Enter number: ").strip()
    return options[int(choice) - 1] if choice.isdigit() and 1 <= int(choice) <= len(options) else "work_meeting"


def load_audio(audio_path):
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")
    wf = wave.open(audio_path, "rb")
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
        raise ValueError("Audio file must be mono channel, 16-bit PCM WAV")
    return wf


def transcribe(audio_path, model_path):
    context = select_context()
    phrases = CONTEXT_PHRASES.get(context, [])
    print(f"\nğŸ¯ Using context: {context.replace('_', ' ').title()}\n")

    if not os.path.isdir(model_path):
        raise FileNotFoundError(f"Model folder not found: {model_path}")

    model = Model(model_path)
    wf = load_audio(audio_path)
    rec = KaldiRecognizer(model, wf.getframerate(), json.dumps(phrases))

    results = []
    while True:
        data = wf.readframes(4000)
        if not data:
            break
        if rec.AcceptWaveform(data):
            results.append(json.loads(rec.Result()))
    results.append(json.loads(rec.FinalResult()))

    transcript = " ".join([res.get("text", "") for res in results])
    print("ğŸ“ Transcript:\n")
    print(transcript)

    with open("transcript.txt", "w", encoding="utf-8") as f:
        f.write(transcript)
    print("\nâœ… Saved to transcript.txt")


if __name__ == "__main__":
    AUDIO_PATH = "my_voice.wav"  # Or "live_recording.wav", etc.
    MODEL_PATH = os.path.join(os.getcwd(), "vosk-model")  # Absolute path for safety

    transcribe(AUDIO_PATH, MODEL_PATH)
