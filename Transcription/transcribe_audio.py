import os
import wave
import json
from vosk import Model, KaldiRecognizer
from pydub import AudioSegment

# ğŸŒ Multilingual context vocabulary (Tunisian Arabic + French + English)
CONTEXT_PHRASES = {
    "angular_tuto": [
    "component", "template", "service", "directive", "module", "pipe", "routing", "formulaire",
    "API", "observable", "rxjs", "async", "subscribe", "interface", "ngOnInit", "binding",
    "two-way", "props", "event", "input", "output", "class", "structure", "ngModel",
    "data", "DOM", "node_modules", "build", "serve", "compilation", "transpiler", "CLI",
    "angular.json", "tsconfig", "html", "css", "typescript", "ts", "javascript", "assets",
    "ÙˆØ§Ø¬Ù‡Ø©", "ØªØ·Ø¨ÙŠÙ‚", "Ù…Ø´Ø±ÙˆØ¹", "ÙƒÙˆÙ…Ø¨ÙˆÙ†ÙˆÙ†", "Ù…ÙƒÙˆÙ†", "formulaire", "Ã©vÃ©nement",
    "ØªØ­Ø¯ÙŠØ«", "module dynamique", "installation", "npm", "package", "Ø£ÙˆØ§Ù…Ø±", "commande",
    "ØªØ´ØºÙŠÙ„", "ØªØ·ÙˆÙŠØ±", "Ø¨ÙŠØ¦Ø©", "dev", "production", "import", "export", "service injectable",
    "httpClient", "auth", "ØªØ³Ø¬ÙŠÙ„", "ÙˆØ§Ø¬Ù‡Ø© Ø¯Ø®ÙˆÙ„", "ØªØ³Ø¬ÙŠÙ„ Ø®Ø±ÙˆØ¬", "guard", "route",
    "navigation", "lazy loading", "interceptor", "form reactive", "validation", "erreurs",
    "message d'erreur", "directive personnalisÃ©e", "component imbriquÃ©", "animation"
],

    "networks_fiber": [
        "fiber", "fibre optique", "backbone", "5G", "dÃ©ploiement", "Ø´Ø¨ÙƒØ©", "ØªØºØ·ÙŠØ©", "connexion",
        "haut dÃ©bit", "FTTx", "latency", "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±ÙŠØ¶", "capacitÃ©", "architecture rÃ©seau"
    ],
    "it_security": [
        "cybersecurity", "sÃ©curitÃ©", "Ø§Ø®ØªØ±Ø§Ù‚", "firewall", "ØªØ­Ù‚Ù‚", "authentification", "Ù…Ø±Ø§Ù‚Ø¨Ø©",
        "antivirus", "intrusion", "compliance", "SOC", "privileges", "ÙƒÙ„Ù…Ø© Ø³Ø±", "protection", "data leak"
    ],
    "data_ai": [
        "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "machine learning", "model", "donnÃ©es", "data", "analyse prÃ©dictive",
        "predictive maintenance", "Ù…Ø¹Ø§Ù„Ø¬Ø©", "Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©", "algorithm", "Ù†Ù…ÙˆØ°Ø¬", "training", "AI", "optimisation"
    ],
    "consulting_transform": [
        "digital transformation", "ØªØ­ÙˆÙ„ Ø±Ù‚Ù…ÙŠ", "governance", "agile", "scrum", "ØªØ·ÙˆÙŠØ±", "workflow",
        "pilotage", "impact", "pÃ©rimÃ¨tre", "efficacitÃ©", "sustainability", "ØªØºÙŠÙŠØ±", "change management"
    ]
}


def select_context():
    print("ğŸ”§ Select meeting context:")
    options = list(CONTEXT_PHRASES.keys())
    for i, key in enumerate(options, 1):
        print(f"{i}. {key.replace('_', ' ').title()}")
    choice = input("Enter number: ").strip()
    return options[int(choice) - 1] if choice.isdigit() and 1 <= int(choice) <= len(options) else "work_meeting"


def convert_mp3_to_wav(mp3_path, wav_path):
    if not os.path.exists(mp3_path):
        raise FileNotFoundError(f"MP3 file not found: {mp3_path}")
    print("ğŸ”„ Converting MP3 to WAV (mono, 16-bit PCM)...")
    audio = AudioSegment.from_mp3(mp3_path)
    audio = audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)
    audio.export(wav_path, format="wav")
    print("âœ… Conversion complete.")
    return wav_path


def load_audio(wav_path):
    if not os.path.exists(wav_path):
        raise FileNotFoundError(f"WAV file not found: {wav_path}")
    wf = wave.open(wav_path, "rb")
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
        raise ValueError("Audio must be mono channel, 16-bit PCM WAV")
    return wf


def transcribe(mp3_path, model_path):
    context = select_context()
    phrases = CONTEXT_PHRASES.get(context, [])
    print(f"\nğŸ¯ Using context: {context.replace('_', ' ').title()}\n")

    if not os.path.isdir(model_path):
        raise FileNotFoundError(f"Model folder not found: {model_path}")

    # Temporary WAV file path
    wav_path = "converted_temp.wav"
    convert_mp3_to_wav(mp3_path, wav_path)

    model = Model(model_path)
    wf = load_audio(wav_path)
    rec = KaldiRecognizer(model, wf.getframerate(), json.dumps(phrases))

    results = []
    print("ğŸ§  Transcribing...")
    while True:
        data = wf.readframes(4000)
        if not data:
            break
        if rec.AcceptWaveform(data):
            results.append(json.loads(rec.Result()))
    results.append(json.loads(rec.FinalResult()))

    transcript = " ".join([res.get("text", "") for res in results])
    print("ğŸ“ Transcript:\n")
    print(transcript)

    with open("transcript.txt", "w", encoding="utf-8") as f:
        f.write(transcript)
    print("\nâœ… Saved to transcript.txt")

    wf.close()
    os.remove(wav_path)  # Clean up temporary file


if __name__ == "__main__":
    raw_input_path = input("ğŸ™ï¸ Enter path to your MP3 file : ").strip()

    # Clean pasted Windows path: remove quotes, normalize slashes
    cleaned_path = raw_input_path.strip('"').strip("'")
    MP3_PATH = os.path.normpath(cleaned_path)

    MODEL_PATH = os.path.join(os.getcwd(), "vosk-model")  # Adjust if needed

    try:
        transcribe(MP3_PATH, MODEL_PATH)
    except Exception as e:
        print(f"âŒ Error: {e}")

