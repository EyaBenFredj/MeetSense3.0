# Transcription/test_whisper.py
import re
from pathlib import Path
import whisper

from core.acronyms import expander  # once-and-for-all expansion

# --- Regex for classic A-Z acronyms (kept) ---
_ARABIC_BLOCK = "\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF"
ACRONYM_REGEX = rf"(?<![0-9A-Za-z_{_ARABIC_BLOCK}])[A-Z0-9]{{2,8}}(?![0-9A-Za-z_{_ARABIC_BLOCK}])"


# ---------------------------
# Arabic letter-name handling
# ---------------------------

# Single-token collapsed forms Whisper often produces
# e.g. "ÿ≥ÿ®Ÿä" ~= "ÿ•ÿ≥ ÿ®Ÿä" (SP), "ÿ±ŸäŸÖ" ~= "ÿ¢ÿ± ÿ•ŸÖ" (RM)
COLLAPSED_TOKEN_MAP = {
    "ÿ≥ÿ®Ÿä": "SP",
    "ÿ±ŸäŸÖ": "RM",
}

# Multi-token patterns ‚Üí acronym
# (Keep it small & precise to avoid false positives in Tunisian Arabic)
PATTERNS = [
    (("ÿØŸä", "ÿØŸä"), "DD"),
    (("ÿßÿ≥", "ÿ®Ÿä"), "SP"), (("ÿ•ÿ≥", "ÿ®Ÿä"), "SP"),
    (("ÿ≥Ÿä", "ÿßÿ±", "ÿßŸÖ"), "CRM"), (("ÿ≥Ÿä", "ÿ¢ÿ±", "ÿßŸÖ"), "CRM"),
    (("ÿßÿ±", "ÿßŸÖ"), "RM"), (("ÿ¢ÿ±", "ÿßŸÖ"), "RM"),
    (("ÿßŸÖ", "ÿ™Ÿä"), "MT"), (("ÿßŸäŸÖ", "ÿ™Ÿä"), "MT"),
    (("ŸÉŸäŸà", "ÿßŸä"), "QA"), (("ŸÉŸíŸäŸà", "ÿßŸä"), "QA"),  # QA (Quality Assurance)
]

# Arabic spellings of Latin letter names (very conservative list)
LETTER_NAME_MAP = {
    "ÿßŸä": "A", "ÿ¢Ÿä": "I", "ÿ•Ÿä": "E",
    "ÿ®Ÿä": "B",
    "ÿ≥Ÿä": "C",
    "ÿØŸä": "D",
    "ÿßŸÅ": "F", "ÿ•ŸÅ": "F",
    "ÿ¨Ÿä": "G",
    "ÿßÿ™ÿ¥": "H", "ÿ•ÿ™ÿ¥": "H",
    "ŸÉŸä": "K",
    "ÿßŸÖ": "M", "ÿßŸäŸÖ": "M",
    "ÿßŸÜ": "N", "ÿ•ŸÜ": "N", "ÿßŸäŸÜ": "N",
    "ÿßŸà": "O", "ÿ£Ÿà": "O",
    "ŸÉŸäŸà": "Q",
    "ÿßÿ±": "R", "ÿ¢ÿ±": "R",
    "ÿßÿ≥": "S", "ÿ•ÿ≥": "S", "ÿ≥": "S",   # sometimes Whisper drops the alif
    "ÿ™Ÿä": "T",
    "ŸäŸà": "U",
    "ŸÅŸä": "V",
    "ÿßŸÉÿ≥": "X", "ÿ•ŸÉÿ≥": "X",
    "ŸàÿßŸä": "Y",
    "ÿ≤ÿØ": "Z", "ÿ≤ŸäŸÜ": "Z", "ÿ≤Ÿä": "Z",
}

PUNCT_RX = re.compile(r"^[\W_]+|[\W_]+$")


def _strip_punct(tok: str):
    """Return (core, left_punct, right_punct)."""
    left = ""
    right = ""
    m = re.match(r"^[\W_]+", tok)
    if m:
        left = m.group(0)
        tok = tok[len(left):]
    m = re.search(r"[\W_]+$", tok)
    if m:
        right = m.group(0)
        tok = tok[:-len(right)]
    return tok, left, right


def normalize_ar_letter_names_to_acronyms(text: str) -> str:
    """
    Convert sequences like:
      'ÿØŸä ÿØŸä ÿ≥ÿ®Ÿä' ‚Üí 'DD SP'
      'ÿßŸäŸÖ ÿ™Ÿä'   ‚Üí 'MT'
      'ŸÉŸäŸà ÿßŸä'   ‚Üí 'QA'
      'ÿ≥Ÿä ÿ±ŸäŸÖ'   ‚Üí 'CRM' (via 'ÿ≥Ÿä' + 'ÿ±ŸäŸÖ'‚Üí'RM')
    and also map any run of Arabic letter names (length>=2) to an acronym.
    """
    if not text:
        return text

    words = text.split()
    out = []
    i = 0
    n = len(words)

    while i < n:
        raw = words[i]
        core, left_p, right_p = _strip_punct(raw)

        # 1) collapsed one-token (e.g., "ÿ≥ÿ®Ÿä", "ÿ±ŸäŸÖ")
        if core in COLLAPSED_TOKEN_MAP:
            out.append(left_p + COLLAPSED_TOKEN_MAP[core] + right_p)
            i += 1
            continue

        # 2) multi-token patterns (try longest first)
        matched = False
        for pat, acro in PATTERNS:
            mlen = len(pat)
            if i + mlen <= n:
                window = [ _strip_punct(w)[0] for w in words[i:i+mlen] ]
                if tuple(window) == pat:
                    out.append(acro)
                    i += mlen
                    matched = True
                    break
        if matched:
            continue

        # 3) generic run of Arabic letter names ‚Üí acronym (length >= 2)
        j = i
        letters = []
        while j < n:
            w_core = _strip_punct(words[j])[0]
            if w_core in LETTER_NAME_MAP:
                letters.append(LETTER_NAME_MAP[w_core])
                j += 1
            else:
                break
        if len(letters) >= 2:
            out.append("".join(letters))
            i = j
            continue

        # 4) default: keep as-is
        out.append(words[i])
        i += 1

    return " ".join(out)


# ---------------------------
# Classic helpers
# ---------------------------

def find_raw_acronyms(text: str):
    return sorted(set(re.findall(ACRONYM_REGEX, text))) if text else []


def transcribe_audio(audio_path: str) -> str:
    """
    Use Whisper; large-v2 handles mixed Arabic/French/English better.
    If you prefer your older model, change 'large-v2' to what you used.
    """
    model = whisper.load_model("large-v2")
    result = model.transcribe(audio_path, language=None, fp16=False)
    return result.get("text", "").strip()


def main():
    audio_path = input(r'Enter the path to your audio file (e.g. MP3/WAV/M4A): ').strip('"').strip()
    if not Path(audio_path).exists():
        print(f"‚ùå File not found: {audio_path}")
        return

    print("üîä Transcribing audio with Whisper (large-v2, multilingual)‚Ä¶")
    transcript = transcribe_audio(audio_path)

    print("\nüìù Transcript (raw):\n")
    print(transcript or "(empty)")

    # --- Normalize Arabic letter-names to real acronyms ---
    normalized = normalize_ar_letter_names_to_acronyms(transcript)

    # --- Detect acronyms after normalization ---
    found = find_raw_acronyms(normalized)
    print("\nüîé Acronyms spotted:", found if found else "none")

    # --- Expand acronyms once-and-for-all ---
    expanded = expander.expand(normalized)
    print("\nüß© Transcript (acronyms expanded):\n")
    print(expanded or "(empty)")

    # Save if you want
    with open("whisper_transcript.txt", "w", encoding="utf-8") as f:
        f.write(expanded)

    print("\n‚úÖ Saved to 'whisper_transcript.txt'")


if __name__ == "__main__":
    main()
